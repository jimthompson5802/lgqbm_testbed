{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 3.2.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, Booster\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(f\"lightgbm version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "# Replace 'train.csv' and 'test.csv' with your actual file paths\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Assuming 'target' is your target variable\n",
    "# Modify these according to your actual feature and target columns\n",
    "X = train_data.drop('target', axis=1)\n",
    "y = train_data['target']\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.61994\n",
      "[2]\tvalid_0's binary_logloss: 0.559848\n",
      "[3]\tvalid_0's binary_logloss: 0.510197\n",
      "[4]\tvalid_0's binary_logloss: 0.468044\n",
      "[5]\tvalid_0's binary_logloss: 0.432372\n",
      "[6]\tvalid_0's binary_logloss: 0.4022\n",
      "[7]\tvalid_0's binary_logloss: 0.376218\n",
      "[8]\tvalid_0's binary_logloss: 0.353479\n",
      "[9]\tvalid_0's binary_logloss: 0.33374\n",
      "[10]\tvalid_0's binary_logloss: 0.316868\n",
      "[11]\tvalid_0's binary_logloss: 0.302091\n",
      "[12]\tvalid_0's binary_logloss: 0.289117\n",
      "[13]\tvalid_0's binary_logloss: 0.277986\n",
      "[14]\tvalid_0's binary_logloss: 0.268068\n",
      "[15]\tvalid_0's binary_logloss: 0.2593\n",
      "[16]\tvalid_0's binary_logloss: 0.251863\n",
      "[17]\tvalid_0's binary_logloss: 0.245192\n",
      "[18]\tvalid_0's binary_logloss: 0.239468\n",
      "[19]\tvalid_0's binary_logloss: 0.234108\n",
      "[20]\tvalid_0's binary_logloss: 0.229936\n",
      "[21]\tvalid_0's binary_logloss: 0.225798\n",
      "[22]\tvalid_0's binary_logloss: 0.222088\n",
      "[23]\tvalid_0's binary_logloss: 0.218774\n",
      "[24]\tvalid_0's binary_logloss: 0.216127\n",
      "[25]\tvalid_0's binary_logloss: 0.21406\n",
      "[26]\tvalid_0's binary_logloss: 0.211919\n",
      "[27]\tvalid_0's binary_logloss: 0.21012\n",
      "[28]\tvalid_0's binary_logloss: 0.208764\n",
      "[29]\tvalid_0's binary_logloss: 0.206646\n",
      "[30]\tvalid_0's binary_logloss: 0.205958\n",
      "[31]\tvalid_0's binary_logloss: 0.205001\n",
      "[32]\tvalid_0's binary_logloss: 0.203692\n",
      "[33]\tvalid_0's binary_logloss: 0.202762\n",
      "[34]\tvalid_0's binary_logloss: 0.202287\n",
      "[35]\tvalid_0's binary_logloss: 0.202198\n",
      "[36]\tvalid_0's binary_logloss: 0.201617\n",
      "[37]\tvalid_0's binary_logloss: 0.201186\n",
      "[38]\tvalid_0's binary_logloss: 0.201032\n",
      "[39]\tvalid_0's binary_logloss: 0.200758\n",
      "[40]\tvalid_0's binary_logloss: 0.200699\n",
      "[41]\tvalid_0's binary_logloss: 0.199963\n",
      "[42]\tvalid_0's binary_logloss: 0.199539\n",
      "[43]\tvalid_0's binary_logloss: 0.199006\n",
      "[44]\tvalid_0's binary_logloss: 0.199043\n",
      "[45]\tvalid_0's binary_logloss: 0.199302\n",
      "[46]\tvalid_0's binary_logloss: 0.199118\n",
      "[47]\tvalid_0's binary_logloss: 0.199045\n",
      "[48]\tvalid_0's binary_logloss: 0.198913\n",
      "[49]\tvalid_0's binary_logloss: 0.198679\n",
      "[50]\tvalid_0's binary_logloss: 0.198551\n",
      "[51]\tvalid_0's binary_logloss: 0.198689\n",
      "[52]\tvalid_0's binary_logloss: 0.198556\n",
      "[53]\tvalid_0's binary_logloss: 0.198281\n",
      "[54]\tvalid_0's binary_logloss: 0.198301\n",
      "[55]\tvalid_0's binary_logloss: 0.198305\n",
      "[56]\tvalid_0's binary_logloss: 0.197878\n",
      "[57]\tvalid_0's binary_logloss: 0.197762\n",
      "[58]\tvalid_0's binary_logloss: 0.197861\n",
      "[59]\tvalid_0's binary_logloss: 0.197848\n",
      "[60]\tvalid_0's binary_logloss: 0.197698\n",
      "[61]\tvalid_0's binary_logloss: 0.197592\n",
      "[62]\tvalid_0's binary_logloss: 0.197452\n",
      "[63]\tvalid_0's binary_logloss: 0.197276\n",
      "[64]\tvalid_0's binary_logloss: 0.197444\n",
      "[65]\tvalid_0's binary_logloss: 0.197339\n",
      "[66]\tvalid_0's binary_logloss: 0.197047\n",
      "[67]\tvalid_0's binary_logloss: 0.197097\n",
      "[68]\tvalid_0's binary_logloss: 0.196976\n",
      "[69]\tvalid_0's binary_logloss: 0.197299\n",
      "[70]\tvalid_0's binary_logloss: 0.197659\n",
      "[71]\tvalid_0's binary_logloss: 0.198056\n",
      "[72]\tvalid_0's binary_logloss: 0.198102\n",
      "[73]\tvalid_0's binary_logloss: 0.198181\n",
      "[74]\tvalid_0's binary_logloss: 0.198143\n",
      "[75]\tvalid_0's binary_logloss: 0.197943\n",
      "[76]\tvalid_0's binary_logloss: 0.198151\n",
      "[77]\tvalid_0's binary_logloss: 0.198568\n",
      "[78]\tvalid_0's binary_logloss: 0.198984\n",
      "[79]\tvalid_0's binary_logloss: 0.198795\n",
      "[80]\tvalid_0's binary_logloss: 0.198808\n",
      "[81]\tvalid_0's binary_logloss: 0.198866\n",
      "[82]\tvalid_0's binary_logloss: 0.199152\n",
      "[83]\tvalid_0's binary_logloss: 0.199505\n",
      "[84]\tvalid_0's binary_logloss: 0.199059\n",
      "[85]\tvalid_0's binary_logloss: 0.198891\n",
      "[86]\tvalid_0's binary_logloss: 0.199276\n",
      "[87]\tvalid_0's binary_logloss: 0.199352\n",
      "[88]\tvalid_0's binary_logloss: 0.199374\n",
      "[89]\tvalid_0's binary_logloss: 0.199426\n",
      "[90]\tvalid_0's binary_logloss: 0.199293\n",
      "[91]\tvalid_0's binary_logloss: 0.199248\n",
      "[92]\tvalid_0's binary_logloss: 0.19965\n",
      "[93]\tvalid_0's binary_logloss: 0.199585\n",
      "[94]\tvalid_0's binary_logloss: 0.199699\n",
      "[95]\tvalid_0's binary_logloss: 0.199722\n",
      "[96]\tvalid_0's binary_logloss: 0.199594\n",
      "[97]\tvalid_0's binary_logloss: 0.199533\n",
      "[98]\tvalid_0's binary_logloss: 0.199662\n",
      "[99]\tvalid_0's binary_logloss: 0.199864\n",
      "[100]\tvalid_0's binary_logloss: 0.200049\n",
      "\n",
      "Test Acc: 0.9331\n",
      "Test AUC: 0.9330\n",
      "\n",
      "Test Acc: 0.9495\n",
      "Test AUC: 0.9495\n",
      "[[0.00776503 0.99223497]\n",
      " [0.10478753 0.89521247]\n",
      " [0.04977558 0.95022442]\n",
      " [0.99188038 0.00811962]\n",
      " [0.85409501 0.14590499]\n",
      " [0.01003624 0.98996376]\n",
      " [0.00363611 0.99636389]\n",
      " [0.97778551 0.02221449]\n",
      " [0.06912174 0.93087826]\n",
      " [0.12317774 0.87682226]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "\n",
    ")\n",
    "\n",
    "# Make predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate binary classification model\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "val_roc_auc = roc_auc_score(y_val, val_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {val_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "model1_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(model1_proba[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff173015d0>\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : array-like of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data.\n",
      "    init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of strings or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "        Weights of eval data.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of arrays or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of arrays or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : string, callable, list or None, optional (default=None)\n",
      "        If string, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    early_stopping_rounds : int or None, optional (default=None)\n",
      "        Activates early stopping. The model will train until the validation score stops improving.\n",
      "        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      "        to continue training.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      "        To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n",
      "        in additional parameters ``**kwargs`` of the model constructor.\n",
      "    verbose : bool or int, optional (default=True)\n",
      "        Requires at least one evaluation data.\n",
      "        If True, the eval metric on the eval set is printed at each boosting stage.\n",
      "        If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n",
      "        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "\n",
      "        .. rubric:: Example\n",
      "\n",
      "        With ``verbose`` = 4 and at least one item in ``eval_set``,\n",
      "        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "\n",
      "    feature_name : list of strings or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "    callbacks : list of callback functions or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : string, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : array-like of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "        weight : array-like of shape = [n_samples]\n",
      "            The weight of samples.\n",
      "        group : array-like\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : string\n",
      "            The name of evaluation function (without whitespaces).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "    For binary task, the y_pred is probability of positive class (or margin in case of custom ``objective``).\n",
      "    For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      "_class_map {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_doc_link_module sklearn\n",
      "_doc_link_template https://scikit-learn.org/1.6/modules/generated/{estimator_module}.{estimator_name}.html\n",
      "_doc_link_url_param_generator None\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff173015d0>\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      "colsample_bytree 1.0\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      "feature_importances_ [269 135 330 350 265 187 208 160 125 200]\n",
      "feature_name_ ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      "n_estimators 100\n",
      "n_features_ 10\n",
      "n_features_in_ 10\n",
      "n_jobs -1\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n"
     ]
    }
   ],
   "source": [
    "for p in dir(model):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(model, p)):\n",
    "        print(p, getattr(model, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.txt\n"
     ]
    }
   ],
   "source": [
    "# save model to pickle file\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "#save the model tree structure                  \n",
    "model.booster_.save_model('model.txt')\n",
    "print(\"Model saved as model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff1694b050>\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : array-like of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data.\n",
      "    init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of strings or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "        Weights of eval data.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of arrays or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of arrays or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : string, callable, list or None, optional (default=None)\n",
      "        If string, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    early_stopping_rounds : int or None, optional (default=None)\n",
      "        Activates early stopping. The model will train until the validation score stops improving.\n",
      "        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      "        to continue training.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      "        To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n",
      "        in additional parameters ``**kwargs`` of the model constructor.\n",
      "    verbose : bool or int, optional (default=True)\n",
      "        Requires at least one evaluation data.\n",
      "        If True, the eval metric on the eval set is printed at each boosting stage.\n",
      "        If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n",
      "        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "\n",
      "        .. rubric:: Example\n",
      "\n",
      "        With ``verbose`` = 4 and at least one item in ``eval_set``,\n",
      "        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "\n",
      "    feature_name : list of strings or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "    callbacks : list of callback functions or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : string, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : array-like of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "        weight : array-like of shape = [n_samples]\n",
      "            The weight of samples.\n",
      "        group : array-like\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : string\n",
      "            The name of evaluation function (without whitespaces).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "    For binary task, the y_pred is probability of positive class (or margin in case of custom ``objective``).\n",
      "    For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      "_class_map {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_doc_link_module sklearn\n",
      "_doc_link_template https://scikit-learn.org/1.6/modules/generated/{estimator_module}.{estimator_name}.html\n",
      "_doc_link_url_param_generator None\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      ">>>>>>Error setting best_iteration_\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      ">>>>>>Error setting best_score_\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff1694b050>\n",
      ">>>>>>Error setting booster_\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      ">>>>>>Error setting classes_\n",
      "colsample_bytree 1.0\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      ">>>>>>Error setting evals_result_\n",
      "feature_importances_ [269 135 330 350 265 187 208 160 125 200]\n",
      ">>>>>>Error setting feature_importances_\n",
      "feature_name_ ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
      ">>>>>>Error setting feature_name_\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      ">>>>>>Error setting n_classes_\n",
      "n_estimators 100\n",
      "n_features_ 10\n",
      ">>>>>>Error setting n_features_\n",
      "n_features_in_ 10\n",
      ">>>>>>Error setting n_features_in_\n",
      "n_jobs -1\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      ">>>>>>Error setting objective_\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n",
      "\n",
      "Test Acc: 0.9495\n",
      "Test AUC: 0.9495\n",
      "probabilities the same True\n"
     ]
    }
   ],
   "source": [
    "booster_model = Booster(\n",
    "    model_file='model.txt'\n",
    ")\n",
    "\n",
    "# restore model from pickle file\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    orig_model = pickle.load(f)\n",
    "\n",
    "\n",
    "# create stub classier\n",
    "model2 = LGBMClassifier()\n",
    "\n",
    "# populae the stub classifier with the attributes of the original model\n",
    "for p in dir(orig_model):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(orig_model, p)):\n",
    "        print(p, getattr(orig_model, p))\n",
    "        try:\n",
    "            setattr(model2, p, getattr(orig_model, p))\n",
    "        except:\n",
    "            print(f\">>>>>>Error setting {p}\")\n",
    "\n",
    "\n",
    "# Load the booster model into the new classifier\n",
    "model2._Booster = booster_model\n",
    "model2.fitted_ = True\n",
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = model2.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "model2_proba = model2.predict_proba(X_test)\n",
    "\n",
    "# Check if the probability predictions are the same\n",
    "print(f\"probabilities the same {np.allclose(model1_proba, model2_proba)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
