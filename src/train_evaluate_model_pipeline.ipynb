{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 3.2.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, Booster\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(f\"lightgbm version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "# Replace 'train.csv' and 'test.csv' with your actual file paths\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Assuming 'target' is your target variable\n",
    "# Modify these according to your actual feature and target columns\n",
    "X = train_data.drop('target', axis=1)\n",
    "y = train_data['target']\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipline with lgbm classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lgbm\", LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, num_leaves=31, random_state=42))                      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Acc: 0.9350\n",
      "Test AUC: 0.9349\n",
      "\n",
      "Test Acc: 0.9510\n",
      "Test AUC: 0.9510\n",
      "[[0.00803537 0.99196463]\n",
      " [0.05653244 0.94346756]\n",
      " [0.04401297 0.95598703]\n",
      " [0.99335159 0.00664841]\n",
      " [0.84520952 0.15479048]\n",
      " [0.00725711 0.99274289]\n",
      " [0.00394439 0.99605561]\n",
      " [0.97750684 0.02249316]\n",
      " [0.03604028 0.96395972]\n",
      " [0.13477993 0.86522007]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "pipeline.fit(\n",
    "    X_train, y_train,\n",
    "    lgbm__eval_set=[(X_val, y_val)],\n",
    "    lgbm__verbose=False,\n",
    "\n",
    ")\n",
    "\n",
    "# Make predictions on validation set\n",
    "val_predictions = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate binary classification model\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "val_roc_auc = roc_auc_score(y_val, val_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {val_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "model1_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "print(model1_proba[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lgbm', LGBMClassifier(max_depth=5, random_state=42))])\n",
      "LGBMClassifier(max_depth=5, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(pipeline)\n",
    "print(pipeline.named_steps['lgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff25aa8f50>\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : array-like of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data.\n",
      "    init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of strings or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "        Weights of eval data.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of arrays or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of arrays or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : string, callable, list or None, optional (default=None)\n",
      "        If string, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    early_stopping_rounds : int or None, optional (default=None)\n",
      "        Activates early stopping. The model will train until the validation score stops improving.\n",
      "        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      "        to continue training.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      "        To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n",
      "        in additional parameters ``**kwargs`` of the model constructor.\n",
      "    verbose : bool or int, optional (default=True)\n",
      "        Requires at least one evaluation data.\n",
      "        If True, the eval metric on the eval set is printed at each boosting stage.\n",
      "        If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n",
      "        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "\n",
      "        .. rubric:: Example\n",
      "\n",
      "        With ``verbose`` = 4 and at least one item in ``eval_set``,\n",
      "        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "\n",
      "    feature_name : list of strings or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "    callbacks : list of callback functions or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : string, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : array-like of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "        weight : array-like of shape = [n_samples]\n",
      "            The weight of samples.\n",
      "        group : array-like\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : string\n",
      "            The name of evaluation function (without whitespaces).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "    For binary task, the y_pred is probability of positive class (or margin in case of custom ``objective``).\n",
      "    For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.24494811239205372))])})\n",
      "_class_map {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_doc_link_module sklearn\n",
      "_doc_link_template https://scikit-learn.org/1.5/modules/generated/{estimator_module}.{estimator_name}.html\n",
      "_doc_link_url_param_generator None\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.622451472450326), np.float64(0.5640742468663879), np.float64(0.5161954200573156), np.float64(0.47520175498936174), np.float64(0.4422169575923951), np.float64(0.41339636783024153), np.float64(0.3881670127190147), np.float64(0.3671966612913902), np.float64(0.34846564610303915), np.float64(0.33257361806326075), np.float64(0.31854994749396026), np.float64(0.3071133979754012), np.float64(0.29601818111179445), np.float64(0.2869151657469304), np.float64(0.27884594715502886), np.float64(0.272000162321004), np.float64(0.26566794532012844), np.float64(0.26067114850636286), np.float64(0.2557461382190177), np.float64(0.2525005950608412), np.float64(0.24857188035193598), np.float64(0.24663213688614252), np.float64(0.2446564101044998), np.float64(0.24270189799289413), np.float64(0.24087191142326905), np.float64(0.23962434709618585), np.float64(0.238599960067231), np.float64(0.23744286308866344), np.float64(0.2377353754546885), np.float64(0.2366048788629743), np.float64(0.23551194411506038), np.float64(0.23519218722558594), np.float64(0.2346584923604456), np.float64(0.23394259255677238), np.float64(0.23379339722927528), np.float64(0.2344077471917477), np.float64(0.23406258827247242), np.float64(0.2339106554638375), np.float64(0.23351092313976088), np.float64(0.2338699196380455), np.float64(0.23365203897826356), np.float64(0.23345291583876787), np.float64(0.23311198209446118), np.float64(0.23294347149751563), np.float64(0.23348980884509607), np.float64(0.23370821117504118), np.float64(0.23428423450785205), np.float64(0.2346785111675607), np.float64(0.23497667527342586), np.float64(0.23492097789654245), np.float64(0.23499496943484144), np.float64(0.23540424406620822), np.float64(0.23527511366981924), np.float64(0.23547501521419784), np.float64(0.2354533453893255), np.float64(0.23554072815736213), np.float64(0.2364234584371674), np.float64(0.23586134196772943), np.float64(0.23627033457119467), np.float64(0.2363369551229659), np.float64(0.23706447430638103), np.float64(0.23684036433879987), np.float64(0.23648040629775735), np.float64(0.2363825113682473), np.float64(0.2361025633297508), np.float64(0.23588977970186195), np.float64(0.23595758820651638), np.float64(0.2367887376522173), np.float64(0.23680289105538932), np.float64(0.2367783570981582), np.float64(0.23783673891972984), np.float64(0.237754247099788), np.float64(0.23790264093645702), np.float64(0.23842661787554598), np.float64(0.23905946380813325), np.float64(0.23958387863535616), np.float64(0.23991909621627744), np.float64(0.23988689267477598), np.float64(0.239999775242953), np.float64(0.2407988797527143), np.float64(0.2409242721527866), np.float64(0.2408711595049189), np.float64(0.24091417767087264), np.float64(0.2412609720619352), np.float64(0.2416449187747535), np.float64(0.24214993893092024), np.float64(0.24261168665693242), np.float64(0.24245658854841623), np.float64(0.2427434454115014), np.float64(0.2424357463679045), np.float64(0.24274508155113103), np.float64(0.24356656398354143), np.float64(0.24409857118495304), np.float64(0.2439643684313583), np.float64(0.24499191117697708), np.float64(0.2448384902546497), np.float64(0.2444738146901536), np.float64(0.24490111246924), np.float64(0.24508315593210375), np.float64(0.24494811239205372)])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.24494811239205372))])})\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff25aa8f50>\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      "colsample_bytree 1.0\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.622451472450326), np.float64(0.5640742468663879), np.float64(0.5161954200573156), np.float64(0.47520175498936174), np.float64(0.4422169575923951), np.float64(0.41339636783024153), np.float64(0.3881670127190147), np.float64(0.3671966612913902), np.float64(0.34846564610303915), np.float64(0.33257361806326075), np.float64(0.31854994749396026), np.float64(0.3071133979754012), np.float64(0.29601818111179445), np.float64(0.2869151657469304), np.float64(0.27884594715502886), np.float64(0.272000162321004), np.float64(0.26566794532012844), np.float64(0.26067114850636286), np.float64(0.2557461382190177), np.float64(0.2525005950608412), np.float64(0.24857188035193598), np.float64(0.24663213688614252), np.float64(0.2446564101044998), np.float64(0.24270189799289413), np.float64(0.24087191142326905), np.float64(0.23962434709618585), np.float64(0.238599960067231), np.float64(0.23744286308866344), np.float64(0.2377353754546885), np.float64(0.2366048788629743), np.float64(0.23551194411506038), np.float64(0.23519218722558594), np.float64(0.2346584923604456), np.float64(0.23394259255677238), np.float64(0.23379339722927528), np.float64(0.2344077471917477), np.float64(0.23406258827247242), np.float64(0.2339106554638375), np.float64(0.23351092313976088), np.float64(0.2338699196380455), np.float64(0.23365203897826356), np.float64(0.23345291583876787), np.float64(0.23311198209446118), np.float64(0.23294347149751563), np.float64(0.23348980884509607), np.float64(0.23370821117504118), np.float64(0.23428423450785205), np.float64(0.2346785111675607), np.float64(0.23497667527342586), np.float64(0.23492097789654245), np.float64(0.23499496943484144), np.float64(0.23540424406620822), np.float64(0.23527511366981924), np.float64(0.23547501521419784), np.float64(0.2354533453893255), np.float64(0.23554072815736213), np.float64(0.2364234584371674), np.float64(0.23586134196772943), np.float64(0.23627033457119467), np.float64(0.2363369551229659), np.float64(0.23706447430638103), np.float64(0.23684036433879987), np.float64(0.23648040629775735), np.float64(0.2363825113682473), np.float64(0.2361025633297508), np.float64(0.23588977970186195), np.float64(0.23595758820651638), np.float64(0.2367887376522173), np.float64(0.23680289105538932), np.float64(0.2367783570981582), np.float64(0.23783673891972984), np.float64(0.237754247099788), np.float64(0.23790264093645702), np.float64(0.23842661787554598), np.float64(0.23905946380813325), np.float64(0.23958387863535616), np.float64(0.23991909621627744), np.float64(0.23988689267477598), np.float64(0.239999775242953), np.float64(0.2407988797527143), np.float64(0.2409242721527866), np.float64(0.2408711595049189), np.float64(0.24091417767087264), np.float64(0.2412609720619352), np.float64(0.2416449187747535), np.float64(0.24214993893092024), np.float64(0.24261168665693242), np.float64(0.24245658854841623), np.float64(0.2427434454115014), np.float64(0.2424357463679045), np.float64(0.24274508155113103), np.float64(0.24356656398354143), np.float64(0.24409857118495304), np.float64(0.2439643684313583), np.float64(0.24499191117697708), np.float64(0.2448384902546497), np.float64(0.2444738146901536), np.float64(0.24490111246924), np.float64(0.24508315593210375), np.float64(0.24494811239205372)])])}\n",
      "feature_importances_ [284 122 335 334 279 171 179 195 133 187]\n",
      "feature_name_ ['Column_0', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5', 'Column_6', 'Column_7', 'Column_8', 'Column_9']\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      "n_estimators 100\n",
      "n_features_ 10\n",
      "n_features_in_ 10\n",
      "n_jobs -1\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = pipeline.named_steps['lgbm']\n",
    "\n",
    "for p in dir(lgbm_model):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(lgbm_model, p)):\n",
    "        print(p, getattr(lgbm_model, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.txt\n"
     ]
    }
   ],
   "source": [
    "# save model to pickle file\n",
    "with open('pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "#save the model tree structure                  \n",
    "pipeline.named_steps[\"lgbm\"].booster_.save_model('model.txt')\n",
    "print(\"Model saved as model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff216d8e50>\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : array-like of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data.\n",
      "    init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of strings or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "        Weights of eval data.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of arrays or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of arrays or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : string, callable, list or None, optional (default=None)\n",
      "        If string, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    early_stopping_rounds : int or None, optional (default=None)\n",
      "        Activates early stopping. The model will train until the validation score stops improving.\n",
      "        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      "        to continue training.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      "        To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n",
      "        in additional parameters ``**kwargs`` of the model constructor.\n",
      "    verbose : bool or int, optional (default=True)\n",
      "        Requires at least one evaluation data.\n",
      "        If True, the eval metric on the eval set is printed at each boosting stage.\n",
      "        If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n",
      "        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "\n",
      "        .. rubric:: Example\n",
      "\n",
      "        With ``verbose`` = 4 and at least one item in ``eval_set``,\n",
      "        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "\n",
      "    feature_name : list of strings or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "    callbacks : list of callback functions or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : string, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : array-like of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "        weight : array-like of shape = [n_samples]\n",
      "            The weight of samples.\n",
      "        group : array-like\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : string\n",
      "            The name of evaluation function (without whitespaces).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "    For binary task, the y_pred is probability of positive class (or margin in case of custom ``objective``).\n",
      "    For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.24494811239205372))])})\n",
      "_class_map {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_doc_link_module sklearn\n",
      "_doc_link_template https://scikit-learn.org/1.5/modules/generated/{estimator_module}.{estimator_name}.html\n",
      "_doc_link_url_param_generator None\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.622451472450326), np.float64(0.5640742468663879), np.float64(0.5161954200573156), np.float64(0.47520175498936174), np.float64(0.4422169575923951), np.float64(0.41339636783024153), np.float64(0.3881670127190147), np.float64(0.3671966612913902), np.float64(0.34846564610303915), np.float64(0.33257361806326075), np.float64(0.31854994749396026), np.float64(0.3071133979754012), np.float64(0.29601818111179445), np.float64(0.2869151657469304), np.float64(0.27884594715502886), np.float64(0.272000162321004), np.float64(0.26566794532012844), np.float64(0.26067114850636286), np.float64(0.2557461382190177), np.float64(0.2525005950608412), np.float64(0.24857188035193598), np.float64(0.24663213688614252), np.float64(0.2446564101044998), np.float64(0.24270189799289413), np.float64(0.24087191142326905), np.float64(0.23962434709618585), np.float64(0.238599960067231), np.float64(0.23744286308866344), np.float64(0.2377353754546885), np.float64(0.2366048788629743), np.float64(0.23551194411506038), np.float64(0.23519218722558594), np.float64(0.2346584923604456), np.float64(0.23394259255677238), np.float64(0.23379339722927528), np.float64(0.2344077471917477), np.float64(0.23406258827247242), np.float64(0.2339106554638375), np.float64(0.23351092313976088), np.float64(0.2338699196380455), np.float64(0.23365203897826356), np.float64(0.23345291583876787), np.float64(0.23311198209446118), np.float64(0.23294347149751563), np.float64(0.23348980884509607), np.float64(0.23370821117504118), np.float64(0.23428423450785205), np.float64(0.2346785111675607), np.float64(0.23497667527342586), np.float64(0.23492097789654245), np.float64(0.23499496943484144), np.float64(0.23540424406620822), np.float64(0.23527511366981924), np.float64(0.23547501521419784), np.float64(0.2354533453893255), np.float64(0.23554072815736213), np.float64(0.2364234584371674), np.float64(0.23586134196772943), np.float64(0.23627033457119467), np.float64(0.2363369551229659), np.float64(0.23706447430638103), np.float64(0.23684036433879987), np.float64(0.23648040629775735), np.float64(0.2363825113682473), np.float64(0.2361025633297508), np.float64(0.23588977970186195), np.float64(0.23595758820651638), np.float64(0.2367887376522173), np.float64(0.23680289105538932), np.float64(0.2367783570981582), np.float64(0.23783673891972984), np.float64(0.237754247099788), np.float64(0.23790264093645702), np.float64(0.23842661787554598), np.float64(0.23905946380813325), np.float64(0.23958387863535616), np.float64(0.23991909621627744), np.float64(0.23988689267477598), np.float64(0.239999775242953), np.float64(0.2407988797527143), np.float64(0.2409242721527866), np.float64(0.2408711595049189), np.float64(0.24091417767087264), np.float64(0.2412609720619352), np.float64(0.2416449187747535), np.float64(0.24214993893092024), np.float64(0.24261168665693242), np.float64(0.24245658854841623), np.float64(0.2427434454115014), np.float64(0.2424357463679045), np.float64(0.24274508155113103), np.float64(0.24356656398354143), np.float64(0.24409857118495304), np.float64(0.2439643684313583), np.float64(0.24499191117697708), np.float64(0.2448384902546497), np.float64(0.2444738146901536), np.float64(0.24490111246924), np.float64(0.24508315593210375), np.float64(0.24494811239205372)])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      ">>>>>>Error setting best_iteration_\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.24494811239205372))])})\n",
      ">>>>>>Error setting best_score_\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff216d8e50>\n",
      ">>>>>>Error setting booster_\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      ">>>>>>Error setting classes_\n",
      "colsample_bytree 1.0\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.622451472450326), np.float64(0.5640742468663879), np.float64(0.5161954200573156), np.float64(0.47520175498936174), np.float64(0.4422169575923951), np.float64(0.41339636783024153), np.float64(0.3881670127190147), np.float64(0.3671966612913902), np.float64(0.34846564610303915), np.float64(0.33257361806326075), np.float64(0.31854994749396026), np.float64(0.3071133979754012), np.float64(0.29601818111179445), np.float64(0.2869151657469304), np.float64(0.27884594715502886), np.float64(0.272000162321004), np.float64(0.26566794532012844), np.float64(0.26067114850636286), np.float64(0.2557461382190177), np.float64(0.2525005950608412), np.float64(0.24857188035193598), np.float64(0.24663213688614252), np.float64(0.2446564101044998), np.float64(0.24270189799289413), np.float64(0.24087191142326905), np.float64(0.23962434709618585), np.float64(0.238599960067231), np.float64(0.23744286308866344), np.float64(0.2377353754546885), np.float64(0.2366048788629743), np.float64(0.23551194411506038), np.float64(0.23519218722558594), np.float64(0.2346584923604456), np.float64(0.23394259255677238), np.float64(0.23379339722927528), np.float64(0.2344077471917477), np.float64(0.23406258827247242), np.float64(0.2339106554638375), np.float64(0.23351092313976088), np.float64(0.2338699196380455), np.float64(0.23365203897826356), np.float64(0.23345291583876787), np.float64(0.23311198209446118), np.float64(0.23294347149751563), np.float64(0.23348980884509607), np.float64(0.23370821117504118), np.float64(0.23428423450785205), np.float64(0.2346785111675607), np.float64(0.23497667527342586), np.float64(0.23492097789654245), np.float64(0.23499496943484144), np.float64(0.23540424406620822), np.float64(0.23527511366981924), np.float64(0.23547501521419784), np.float64(0.2354533453893255), np.float64(0.23554072815736213), np.float64(0.2364234584371674), np.float64(0.23586134196772943), np.float64(0.23627033457119467), np.float64(0.2363369551229659), np.float64(0.23706447430638103), np.float64(0.23684036433879987), np.float64(0.23648040629775735), np.float64(0.2363825113682473), np.float64(0.2361025633297508), np.float64(0.23588977970186195), np.float64(0.23595758820651638), np.float64(0.2367887376522173), np.float64(0.23680289105538932), np.float64(0.2367783570981582), np.float64(0.23783673891972984), np.float64(0.237754247099788), np.float64(0.23790264093645702), np.float64(0.23842661787554598), np.float64(0.23905946380813325), np.float64(0.23958387863535616), np.float64(0.23991909621627744), np.float64(0.23988689267477598), np.float64(0.239999775242953), np.float64(0.2407988797527143), np.float64(0.2409242721527866), np.float64(0.2408711595049189), np.float64(0.24091417767087264), np.float64(0.2412609720619352), np.float64(0.2416449187747535), np.float64(0.24214993893092024), np.float64(0.24261168665693242), np.float64(0.24245658854841623), np.float64(0.2427434454115014), np.float64(0.2424357463679045), np.float64(0.24274508155113103), np.float64(0.24356656398354143), np.float64(0.24409857118495304), np.float64(0.2439643684313583), np.float64(0.24499191117697708), np.float64(0.2448384902546497), np.float64(0.2444738146901536), np.float64(0.24490111246924), np.float64(0.24508315593210375), np.float64(0.24494811239205372)])])}\n",
      ">>>>>>Error setting evals_result_\n",
      "feature_importances_ [284 122 335 334 279 171 179 195 133 187]\n",
      ">>>>>>Error setting feature_importances_\n",
      "feature_name_ ['Column_0', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5', 'Column_6', 'Column_7', 'Column_8', 'Column_9']\n",
      ">>>>>>Error setting feature_name_\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      ">>>>>>Error setting n_classes_\n",
      "n_estimators 100\n",
      "n_features_ 10\n",
      ">>>>>>Error setting n_features_\n",
      "n_features_in_ 10\n",
      ">>>>>>Error setting n_features_in_\n",
      "n_jobs -1\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      ">>>>>>Error setting objective_\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n",
      "\n",
      "Test Acc: 0.9510\n",
      "Test AUC: 0.9510\n",
      "probabilities the same True\n"
     ]
    }
   ],
   "source": [
    "booster_model = Booster(\n",
    "    model_file='model.txt'\n",
    ")\n",
    "\n",
    "# restore pipeline from pickle file\n",
    "with open('pipeline.pkl', 'rb') as f:\n",
    "    pipeline2 = pickle.load(f)\n",
    "\n",
    "\n",
    "# create stub classier\n",
    "model2 = LGBMClassifier()\n",
    "\n",
    "# populae the stub classifier with the attributes of the original model\n",
    "mdl = pipeline2.named_steps['lgbm']\n",
    "for p in dir(mdl):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(mdl, p)):\n",
    "        print(p, getattr(mdl, p))\n",
    "        try:\n",
    "            setattr(model2, p, getattr(mdl, p))\n",
    "        except:\n",
    "            print(f\">>>>>>Error setting {p}\")\n",
    "\n",
    "\n",
    "# Load the booster model into the new classifier\n",
    "model2._Booster = booster_model\n",
    "model2.fitted_ = True\n",
    "\n",
    "pipeline2.set_params(lgbm=model2)\n",
    "\n",
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = pipeline2.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "model2_proba = pipeline2.predict_proba(X_test)\n",
    "\n",
    "# Check if the probability predictions are the same\n",
    "print(f\"probabilities the same {np.allclose(model1_proba, model2_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
