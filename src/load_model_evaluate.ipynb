{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import  Booster, LGBMClassifier\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(f\"lightgbm version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "test_data = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff320b21d0>\n",
      "_LGBMClassifier__is_multiclass False\n",
      ">>>>>>Error setting _LGBMClassifier__is_multiclass\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : numpy array, pandas DataFrame, H2O DataTable's Frame (deprecated), scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data. Weights should be non-negative.\n",
      "    init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of str, or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
      "        Weights of eval data. Weights should be non-negative.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of array (same types as ``group`` supports), or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : str, callable, list or None, optional (default=None)\n",
      "        If str, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    feature_name : list of str, or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "        Floating point numbers in categorical features will be rounded towards 0.\n",
      "    callbacks : list of callable, or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : LGBMClassifier\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : numpy 1-D array of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "            In case of custom ``objective``, predicted values are returned before any transformation,\n",
      "            e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
      "        weight : numpy 1-D array of shape = [n_samples]\n",
      "            The weight of samples. Weights should be non-negative.\n",
      "        group : numpy 1-D array\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : str\n",
      "            The name of evaluation function (without whitespace).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      "_class_map {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_doc_link_module sklearn\n",
      "_doc_link_template https://scikit-learn.org/1.6/modules/generated/{estimator_module}.{estimator_name}.html\n",
      "_doc_link_url_param_generator None\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      ">>>>>>Error setting best_iteration_\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', np.float64(0.2000492838197002))])})\n",
      ">>>>>>Error setting best_score_\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff320b21d0>\n",
      ">>>>>>Error setting booster_\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      ">>>>>>Error setting classes_\n",
      "colsample_bytree 1.0\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [np.float64(0.6199401327456385), np.float64(0.5598477354099523), np.float64(0.5101972838630062), np.float64(0.4680436219647232), np.float64(0.43237183243660054), np.float64(0.40220028729845453), np.float64(0.37621764198931446), np.float64(0.3534793267237804), np.float64(0.33373976316164755), np.float64(0.3168675602613139), np.float64(0.30209053467443847), np.float64(0.28911748094699363), np.float64(0.2779860295914918), np.float64(0.2680676591277538), np.float64(0.2593000037901044), np.float64(0.2518625859584231), np.float64(0.24519188051510124), np.float64(0.23946836730559043), np.float64(0.2341075737156789), np.float64(0.2299360179823825), np.float64(0.22579787702150927), np.float64(0.22208820104258678), np.float64(0.21877393932493885), np.float64(0.21612704659150972), np.float64(0.2140596308529299), np.float64(0.21191939612178953), np.float64(0.2101204671083104), np.float64(0.20876384097408018), np.float64(0.20664620968874478), np.float64(0.20595776546518985), np.float64(0.20500147152481207), np.float64(0.20369240353000106), np.float64(0.20276157396835656), np.float64(0.20228736322385132), np.float64(0.20219830392360802), np.float64(0.20161696163487594), np.float64(0.20118574393872254), np.float64(0.20103164627423525), np.float64(0.20075758430687113), np.float64(0.200699273713077), np.float64(0.19996279967537803), np.float64(0.19953862286105173), np.float64(0.1990061222895023), np.float64(0.19904281189327602), np.float64(0.19930204728405715), np.float64(0.19911808064860295), np.float64(0.19904479396790553), np.float64(0.19891267615832464), np.float64(0.1986790766517246), np.float64(0.1985506235835758), np.float64(0.1986889873065404), np.float64(0.19855634124909424), np.float64(0.19828131079967087), np.float64(0.1983014624019832), np.float64(0.1983047707558006), np.float64(0.1978775024380053), np.float64(0.1977615980053604), np.float64(0.19786075131342717), np.float64(0.19784782120346855), np.float64(0.1976984131357283), np.float64(0.1975922359376694), np.float64(0.19745160228593842), np.float64(0.1972758235659417), np.float64(0.1974443933567958), np.float64(0.19733925376386185), np.float64(0.19704715849096568), np.float64(0.1970973479835017), np.float64(0.19697585079747504), np.float64(0.19729916041138051), np.float64(0.19765927404611128), np.float64(0.1980561187315104), np.float64(0.19810226682647797), np.float64(0.1981805653942252), np.float64(0.19814319355933388), np.float64(0.19794339427776475), np.float64(0.198151113520212), np.float64(0.19856805229357477), np.float64(0.19898362131080408), np.float64(0.19879545485868783), np.float64(0.19880754484512514), np.float64(0.19886648230837886), np.float64(0.19915192070249965), np.float64(0.19950469233038265), np.float64(0.19905898918884457), np.float64(0.19889139659100458), np.float64(0.19927629212954), np.float64(0.19935154074477612), np.float64(0.1993744688178309), np.float64(0.19942624512862447), np.float64(0.19929346729277664), np.float64(0.19924846109347402), np.float64(0.19964990597560914), np.float64(0.19958474189703856), np.float64(0.1996990481125939), np.float64(0.1997217910911207), np.float64(0.19959442916229217), np.float64(0.19953299915512798), np.float64(0.19966190458925226), np.float64(0.19986397693485164), np.float64(0.2000492838197002)])])}\n",
      ">>>>>>Error setting evals_result_\n",
      "feature_importances_ [269 135 330 350 265 187 208 160 125 200]\n",
      ">>>>>>Error setting feature_importances_\n",
      "feature_name_ ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
      ">>>>>>Error setting feature_name_\n",
      "feature_names_in_ ['feature_0' 'feature_1' 'feature_2' 'feature_3' 'feature_4' 'feature_5'\n",
      " 'feature_6' 'feature_7' 'feature_8' 'feature_9']\n",
      ">>>>>>Error setting feature_names_in_\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      ">>>>>>Error setting n_classes_\n",
      "n_estimators 100\n",
      "n_estimators_ 100\n",
      ">>>>>>Error setting n_estimators_\n",
      "n_features_ 10\n",
      ">>>>>>Error setting n_features_\n",
      "n_features_in_ 10\n",
      "n_iter_ 100\n",
      ">>>>>>Error setting n_iter_\n",
      "n_jobs -1\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      ">>>>>>Error setting objective_\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n",
      "\n",
      "Test Acc: 0.9495\n",
      "Test AUC: 0.9495\n",
      "[[0.00776503 0.99223497]\n",
      " [0.10478753 0.89521247]\n",
      " [0.04977558 0.95022442]\n",
      " [0.99188038 0.00811962]\n",
      " [0.85409501 0.14590499]\n",
      " [0.01003624 0.98996376]\n",
      " [0.00363611 0.99636389]\n",
      " [0.97778551 0.02221449]\n",
      " [0.06912174 0.93087826]\n",
      " [0.12317774 0.87682226]]\n"
     ]
    }
   ],
   "source": [
    "booster_model = Booster(\n",
    "    model_file='model.txt'\n",
    ")\n",
    "\n",
    "# restore model from pickle file\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    orig_model = pickle.load(f)\n",
    "\n",
    "\n",
    "# create stub classier\n",
    "model2 = LGBMClassifier()\n",
    "\n",
    "# populae the stub classifier with the attributes of the original model\n",
    "for p in dir(orig_model):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(orig_model, p)):\n",
    "        print(p, getattr(orig_model, p))\n",
    "        try:\n",
    "            setattr(model2, p, getattr(orig_model, p))\n",
    "        except:\n",
    "            print(f\">>>>>>Error setting {p}\")\n",
    "\n",
    "\n",
    "# Load the booster model into the new classifier\n",
    "model2._Booster = booster_model\n",
    "model2.fitted_ = True\n",
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = model2.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "model2_proba = model2.predict_proba(X_test)\n",
    "\n",
    "print(model2_proba[:10])\n",
    "\n",
    "# Save the model as pickle file\n",
    "with open('model2.pkl', 'wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
