{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 4.6.0\n",
      "sklearn version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import  Booster\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sklearn\n",
    "\n",
    "from custom_class import CustomLGBMClassifier\n",
    "\n",
    "\n",
    "print(f\"lightgbm version: {lgb.__version__}\")\n",
    "print(f\"sklearn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "test_data = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the LGBM Claasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lgbm', CustomLGBMClassifier(max_depth=5, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "booster_model = Booster(\n",
    "    model_file='model.txt'\n",
    ")\n",
    "\n",
    "# restore model from pickle file\n",
    "with open('pipeline.pkl', 'rb') as f:\n",
    "    pipeline2 = pickle.load(f)\n",
    "\n",
    "print(pipeline2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': [('scaler', StandardScaler()),\n",
       "  ('lgbm', CustomLGBMClassifier(max_depth=5, random_state=42))],\n",
       " 'memory': None,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': StandardScaler(),\n",
       " 'lgbm': CustomLGBMClassifier(max_depth=5, random_state=42)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Booster <lightgbm.basic.Booster object at 0xffff0ac28220>\n",
      "_LGBMClassifier__is_multiclass False\n",
      ">>>>>>Error setting _LGBMClassifier__is_multiclass\n",
      "_base_doc \n",
      "    Build a gradient boosting model from the training set (X, y).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : numpy array, pandas DataFrame, H2O DataTable's Frame (deprecated), scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
      "        Input feature matrix.\n",
      "    y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
      "        The target values (class labels in classification, real numbers in regression).\n",
      "    sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
      "        Weights of training data. Weights should be non-negative.\n",
      "    init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
      "        Init score of training data.\n",
      "    eval_set : list or None, optional (default=None)\n",
      "        A list of (X, y) tuple pairs to use as validation sets.\n",
      "    eval_names : list of str, or None, optional (default=None)\n",
      "        Names of eval_set.\n",
      "    eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
      "        Weights of eval data. Weights should be non-negative.\n",
      "    eval_class_weight : list or None, optional (default=None)\n",
      "        Class weights of eval data.\n",
      "    eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
      "        Init score of eval data.\n",
      "    eval_group : list of array (same types as ``group`` supports), or None, optional (default=None)\n",
      "        Group data of eval data.\n",
      "    eval_metric : str, callable, list or None, optional (default=None)\n",
      "        If str, it should be a built-in evaluation metric to use.\n",
      "        If callable, it should be a custom evaluation metric, see note below for more details.\n",
      "        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
      "        In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      "        Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      "    feature_name : list of str, or 'auto', optional (default='auto')\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      "        All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "        The output cannot be monotonically constrained with respect to a categorical feature.\n",
      "        Floating point numbers in categorical features will be rounded towards 0.\n",
      "    callbacks : list of callable, or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
      "        Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    self : LGBMClassifier\n",
      "        Returns self.\n",
      "    \n",
      "\n",
      "\n",
      "    Note\n",
      "    ----\n",
      "    Custom eval function expects a callable with following signatures:\n",
      "    ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "    ``func(y_true, y_pred, weight, group)``\n",
      "    and returns (eval_name, eval_result, is_higher_better) or\n",
      "    list of (eval_name, eval_result, is_higher_better):\n",
      "\n",
      "        y_true : numpy 1-D array of shape = [n_samples]\n",
      "            The target values.\n",
      "        y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
      "            The predicted values.\n",
      "            In case of custom ``objective``, predicted values are returned before any transformation,\n",
      "            e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
      "        weight : numpy 1-D array of shape = [n_samples]\n",
      "            The weight of samples. Weights should be non-negative.\n",
      "        group : numpy 1-D array\n",
      "            Group/query data.\n",
      "            Only used in the learning-to-rank task.\n",
      "            sum(group) = n_samples.\n",
      "            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
      "            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
      "        eval_name : str\n",
      "            The name of evaluation function (without whitespace).\n",
      "        eval_result : float\n",
      "            The eval result.\n",
      "        is_higher_better : bool\n",
      "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      "\n",
      "_best_iteration None\n",
      "_best_score defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', 0.24494811239205366)])})\n",
      "_class_map {0: 0, 1: 1}\n",
      "_class_weight None\n",
      "_classes [0 1]\n",
      "_estimator_type classifier\n",
      "_evals_result {'valid_0': OrderedDict([('binary_logloss', [0.6224514724503258, 0.5640742468663876, 0.5161954200573157, 0.47520175498936185, 0.44221695759239504, 0.41339636783024164, 0.38816701271901477, 0.3671966612913902, 0.34846564610303915, 0.33257361806326075, 0.31854994749396026, 0.3071133979754012, 0.29601818111179445, 0.2869151657469304, 0.27884594715502886, 0.27200016232100405, 0.26566794532012844, 0.26067114850636286, 0.2557461382190177, 0.2525005950608412, 0.24857188035193598, 0.24663213688614252, 0.24465641010449982, 0.24270189799289418, 0.24087191142326908, 0.23962434709618585, 0.23859996006723097, 0.23744286308866344, 0.23773537545468856, 0.2366048788629743, 0.23551194411506043, 0.2351921872255859, 0.2346584923604456, 0.23394259255677233, 0.23379339722927525, 0.2344077471917477, 0.2340625882724724, 0.2339106554638375, 0.23351092313976093, 0.23386991963804543, 0.23365203897826356, 0.2334529158387679, 0.23311198209446118, 0.23294347149751565, 0.23348980884509607, 0.2337082111750412, 0.23428423450785213, 0.23467851116756067, 0.23497667527342586, 0.23492097789654245, 0.23499496943484144, 0.23540424406620825, 0.23527511366981926, 0.23547501521419775, 0.2354533453893255, 0.23554072815736213, 0.23642345843716753, 0.23586134196772943, 0.23627033457119467, 0.23633695512296587, 0.237064474306381, 0.23684036433879987, 0.23648040629775735, 0.23638251136824728, 0.23610256332975083, 0.235889779701862, 0.23595758820651638, 0.2367887376522173, 0.2368028910553893, 0.23677835709815823, 0.23783673891972978, 0.237754247099788, 0.237902640936457, 0.23842661787554598, 0.23905946380813323, 0.23958387863535616, 0.23991909621627744, 0.23988689267477598, 0.23999977524295296, 0.24079887975271433, 0.2409242721527866, 0.24087115950491889, 0.24091417767087261, 0.24126097206193517, 0.2416449187747535, 0.2421499389309203, 0.24261168665693233, 0.24245658854841623, 0.2427434454115014, 0.2424357463679044, 0.242745081551131, 0.2435665639835414, 0.24409857118495315, 0.24396436843135827, 0.24499191117697708, 0.24483849025464965, 0.2444738146901536, 0.24490111246923998, 0.24508315593210372, 0.24494811239205366])])}\n",
      "_fobj None\n",
      "_le LabelEncoder()\n",
      "_n_classes 2\n",
      "_n_features 10\n",
      "_n_features_in 10\n",
      "_objective binary\n",
      "_other_params {}\n",
      "best_iteration_ None\n",
      ">>>>>>Error setting best_iteration_\n",
      "best_score_ defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('binary_logloss', 0.24494811239205366)])})\n",
      ">>>>>>Error setting best_score_\n",
      "booster_ <lightgbm.basic.Booster object at 0xffff0ac28220>\n",
      ">>>>>>Error setting booster_\n",
      "boosting_type gbdt\n",
      "class_weight None\n",
      "classes_ [0 1]\n",
      ">>>>>>Error setting classes_\n",
      "colsample_bytree 1.0\n",
      "custom_param 1\n",
      "evals_result_ {'valid_0': OrderedDict([('binary_logloss', [0.6224514724503258, 0.5640742468663876, 0.5161954200573157, 0.47520175498936185, 0.44221695759239504, 0.41339636783024164, 0.38816701271901477, 0.3671966612913902, 0.34846564610303915, 0.33257361806326075, 0.31854994749396026, 0.3071133979754012, 0.29601818111179445, 0.2869151657469304, 0.27884594715502886, 0.27200016232100405, 0.26566794532012844, 0.26067114850636286, 0.2557461382190177, 0.2525005950608412, 0.24857188035193598, 0.24663213688614252, 0.24465641010449982, 0.24270189799289418, 0.24087191142326908, 0.23962434709618585, 0.23859996006723097, 0.23744286308866344, 0.23773537545468856, 0.2366048788629743, 0.23551194411506043, 0.2351921872255859, 0.2346584923604456, 0.23394259255677233, 0.23379339722927525, 0.2344077471917477, 0.2340625882724724, 0.2339106554638375, 0.23351092313976093, 0.23386991963804543, 0.23365203897826356, 0.2334529158387679, 0.23311198209446118, 0.23294347149751565, 0.23348980884509607, 0.2337082111750412, 0.23428423450785213, 0.23467851116756067, 0.23497667527342586, 0.23492097789654245, 0.23499496943484144, 0.23540424406620825, 0.23527511366981926, 0.23547501521419775, 0.2354533453893255, 0.23554072815736213, 0.23642345843716753, 0.23586134196772943, 0.23627033457119467, 0.23633695512296587, 0.237064474306381, 0.23684036433879987, 0.23648040629775735, 0.23638251136824728, 0.23610256332975083, 0.235889779701862, 0.23595758820651638, 0.2367887376522173, 0.2368028910553893, 0.23677835709815823, 0.23783673891972978, 0.237754247099788, 0.237902640936457, 0.23842661787554598, 0.23905946380813323, 0.23958387863535616, 0.23991909621627744, 0.23988689267477598, 0.23999977524295296, 0.24079887975271433, 0.2409242721527866, 0.24087115950491889, 0.24091417767087261, 0.24126097206193517, 0.2416449187747535, 0.2421499389309203, 0.24261168665693233, 0.24245658854841623, 0.2427434454115014, 0.2424357463679044, 0.242745081551131, 0.2435665639835414, 0.24409857118495315, 0.24396436843135827, 0.24499191117697708, 0.24483849025464965, 0.2444738146901536, 0.24490111246923998, 0.24508315593210372, 0.24494811239205366])])}\n",
      ">>>>>>Error setting evals_result_\n",
      "feature_importances_ [284 122 335 334 279 171 179 195 133 187]\n",
      ">>>>>>Error setting feature_importances_\n",
      "feature_name_ ['Column_0', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5', 'Column_6', 'Column_7', 'Column_8', 'Column_9']\n",
      ">>>>>>Error setting feature_name_\n",
      "feature_names_in_ ['Column_0' 'Column_1' 'Column_2' 'Column_3' 'Column_4' 'Column_5'\n",
      " 'Column_6' 'Column_7' 'Column_8' 'Column_9']\n",
      ">>>>>>Error setting feature_names_in_\n",
      "fitted_ True\n",
      "importance_type split\n",
      "learning_rate 0.1\n",
      "max_depth 5\n",
      "min_child_samples 20\n",
      "min_child_weight 0.001\n",
      "min_split_gain 0.0\n",
      "n_classes_ 2\n",
      ">>>>>>Error setting n_classes_\n",
      "n_estimators 100\n",
      "n_estimators_ 100\n",
      ">>>>>>Error setting n_estimators_\n",
      "n_features_ 10\n",
      ">>>>>>Error setting n_features_\n",
      "n_features_in_ 10\n",
      "n_iter_ 100\n",
      ">>>>>>Error setting n_iter_\n",
      "n_jobs None\n",
      "num_leaves 31\n",
      "objective None\n",
      "objective_ binary\n",
      ">>>>>>Error setting objective_\n",
      "random_state 42\n",
      "reg_alpha 0.0\n",
      "reg_lambda 0.0\n",
      "silent True\n",
      "subsample 1.0\n",
      "subsample_for_bin 200000\n",
      "subsample_freq 0\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lgbm', CustomLGBMClassifier(max_depth=5, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create stub classier\n",
    "model2 = CustomLGBMClassifier()\n",
    "\n",
    "# populae the stub classifier with the attributes of the original model\n",
    "mdl = pipeline2.named_steps['lgbm']\n",
    "for p in dir(mdl):\n",
    "    if not p.startswith(\"__\") and not callable(getattr(mdl, p)):\n",
    "        print(p, getattr(mdl, p))\n",
    "        try:\n",
    "            setattr(model2, p, getattr(mdl, p))\n",
    "        except:\n",
    "            print(f\">>>>>>Error setting {p}\")\n",
    "\n",
    "\n",
    "# Load the booster model into the new classifier\n",
    "model2._Booster = booster_model\n",
    "model2.fitted_ = True\n",
    "\n",
    "# overlay the classifier in the pipeline with the reconstructed model\n",
    "# pipeline2.named_steps['lgbm'] = None #model2\n",
    "# pipeline2.__dict__[\"steps\"][1] = (\"lgbm\", model2)\n",
    "pipeline2.set_params(lgbm=model2)\n",
    "\n",
    "print(pipeline2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba with Custom param: 1\n",
      "[LightGBM] [Warning] Unknown parameter: custom_param\n",
      "\n",
      "Test Acc: 0.9510\n",
      "Test AUC: 0.9510\n",
      "predict_proba with Custom param: 1\n",
      "[LightGBM] [Warning] Unknown parameter: custom_param\n",
      "[[0.00803537 0.99196463]\n",
      " [0.05653244 0.94346756]\n",
      " [0.04401297 0.95598703]\n",
      " [0.99335159 0.00664841]\n",
      " [0.84520952 0.15479048]\n",
      " [0.00725711 0.99274289]\n",
      " [0.00394439 0.99605561]\n",
      " [0.97750684 0.02249316]\n",
      " [0.03604028 0.96395972]\n",
      " [0.13477993 0.86522007]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = pipeline2.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "model2_proba = pipeline2.predict_proba(X_test)\n",
    "\n",
    "print(model2_proba[:10])\n",
    "\n",
    "# Save the model as pickle file\n",
    "with open('pipeline3.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse the rebuilt LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lgbm', CustomLGBMClassifier(max_depth=5, random_state=42))])\n",
      "predict_proba with Custom param: 1\n",
      "[LightGBM] [Warning] Unknown parameter: custom_param\n",
      "\n",
      "Test Acc: 0.9510\n",
      "Test AUC: 0.9510\n",
      "predict_proba with Custom param: 1\n",
      "[LightGBM] [Warning] Unknown parameter: custom_param\n",
      "[[0.00803537 0.99196463]\n",
      " [0.05653244 0.94346756]\n",
      " [0.04401297 0.95598703]\n",
      " [0.99335159 0.00664841]\n",
      " [0.84520952 0.15479048]\n",
      " [0.00725711 0.99274289]\n",
      " [0.00394439 0.99605561]\n",
      " [0.97750684 0.02249316]\n",
      " [0.03604028 0.96395972]\n",
      " [0.13477993 0.86522007]]\n",
      "probability match: True\n"
     ]
    }
   ],
   "source": [
    "# restore model from pickle file\n",
    "with open('pipeline3.pkl', 'rb') as f:\n",
    "    pipeline3 = pickle.load(f)\n",
    "\n",
    "print(pipeline3)\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = pipeline3.predict(X_test)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "print()\n",
    "print(f\"Test Acc: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "model3_proba = pipeline3.predict_proba(X_test)\n",
    "\n",
    "print(model3_proba[:10])\n",
    "\n",
    "\n",
    "print(f\"probability match: {np.all(model2_proba == model3_proba)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
